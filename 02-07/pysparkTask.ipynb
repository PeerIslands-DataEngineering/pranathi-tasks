{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Sr-M_gsSeP",
        "outputId": "48bea8a6-95c5-4706-d4c7-fa2f3a366a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Company Name: string (nullable = true)\n",
            " |-- Founded Year: integer (nullable = true)\n",
            " |-- HQ: string (nullable = true)\n",
            " |-- Industry: string (nullable = true)\n",
            " |-- Total Funding: string (nullable = true)\n",
            " |-- ARR: string (nullable = true)\n",
            " |-- Valuation: string (nullable = true)\n",
            " |-- Employees: string (nullable = true)\n",
            " |-- Top Investors: string (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- G2 Rating: double (nullable = true)\n",
            "\n",
            "+------------+------------+--------------------+--------------------+-------------+------+-------------------+---------+--------------------+--------------------+---------+\n",
            "|Company Name|Founded Year|                  HQ|            Industry|Total Funding|   ARR|          Valuation|Employees|       Top Investors|             Product|G2 Rating|\n",
            "+------------+------------+--------------------+--------------------+-------------+------+-------------------+---------+--------------------+--------------------+---------+\n",
            "|   Microsoft|        1975|    Redmond, WA, USA| Enterprise Software|          $1B| $270B|                $3T|  221,000|Bill Gates, Paul ...|Azure, Office 365...|      4.4|\n",
            "|  Salesforce|        1999|San Francisco, CA...|                 CRM|       $65.4M|$37.9B|            $227.8B|   75,000|Halsey Minor, Lar...|Sales Cloud, Serv...|      4.3|\n",
            "|       Adobe|        1982|   San Jose, CA, USA|   Creative Software|        $2.5M|$19.4B|              $240B|   29,945|   Hambrecht & Quist|Creative Cloud, D...|      4.5|\n",
            "|      Oracle|        1977|     Austin, TX, USA|Database & Enterp...|          $2K|$52.9B|              $350B|  143,000|Larry Ellison, Bo...|Oracle Cloud, Net...|      4.0|\n",
            "|         SAP|        1972|   Walldorf, Germany| Enterprise Software|          N/A|$32.5B|              $215B|  107,415|Dietmar Hopp, Kla...|S/4HANA, SuccessF...|      4.1|\n",
            "|      Intuit|        1983|Mountain View, CA...|  Financial Software|        $273M|$14.4B|              $180B|   18,200|Sierra Ventures, ...|QuickBooks, TurboTax|      4.4|\n",
            "|  ServiceNow|        2004|Santa Clara, CA, USA|IT Service Manage...|       $82.5M| $8.9B|              $147B|   20,000|JMI Equity, Sequo...|IT Service Manage...|      4.4|\n",
            "|     Workday|        2005| Pleasanton, CA, USA|        HR & Finance|      $249.9M| $7.3B|               $65B|   18,800|Greylock Partners...|HCM, Financial Ma...|      4.2|\n",
            "|        Zoom|        2011|   San Jose, CA, USA|Video Communications|      $145.5M| $4.5B|               $85B|    7,388|Sequoia Capital, ...|Video Conferencin...|      4.5|\n",
            "|     Shopify|        2006|      Ottawa, Canada|          E-commerce|      $122.3M| $7.1B|               $95B|   11,600|Bessemer, FirstMa...| E-commerce Platform|      4.4|\n",
            "|   Atlassian|        2002|   Sydney, Australia|Collaboration Sof...|         $60M| $3.5B|               $55B|   11,800|      Accel Partners|Jira, Confluence,...|      4.3|\n",
            "|   Snowflake|        2012|    Bozeman, MT, USA|    Data Warehousing|        $1.4B| $2.8B|               $75B|    6,500|Sequoia, ICONIQ, ...| Cloud Data Platform|      4.4|\n",
            "|     HubSpot|        2006|  Cambridge, MA, USA|   Marketing & Sales|      $100.5M| $2.2B|               $32B|    7,600|General Catalyst,...|Marketing Hub, Sa...|      4.4|\n",
            "|    DocuSign|        2003|San Francisco, CA...|  Digital Agreements|      $514.3M| $2.5B|               $10B|    7,336|Kleiner Perkins, ...|eSignature, Contr...|      4.5|\n",
            "|       Slack|        2009|San Francisco, CA...|  Team Communication|        $1.4B| $1.7B|$27.7B (Salesforce)|    2,545|Accel, Andreessen...|Team Messaging Pl...|      4.5|\n",
            "|      Notion|        2013|San Francisco, CA...|        Productivity|        $353M| $400M|               $10B|      800|Index Ventures, S...|All-in-one workspace|      4.7|\n",
            "|     Datadog|        2010|   New York, NY, USA|Monitoring & Anal...|      $147.9M| $2.1B|               $44B|    5,200|ICONIQ, Index Ven...|Infrastructure Mo...|      4.4|\n",
            "|     MongoDB|        2007|   New York, NY, USA|            Database|      $311.2M| $1.7B|               $26B|    4,500|   Sequoia, NEA, USV|Document Database...|      4.5|\n",
            "|        Okta|        2009|San Francisco, CA...| Identity Management|      $230.5M| $2.2B|               $25B|    5,900|Andreessen Horowi...|Identity & Access...|      4.4|\n",
            "|      Twilio|        2008|San Francisco, CA...|      Communications|      $261.3M| $4.1B|               $12B|    7,867|Bessemer, Union S...| Communications APIs|      4.3|\n",
            "+------------+------------+--------------------+--------------------+-------------+------+-------------------+---------+--------------------+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"spark advanced\").getOrCreate()\n",
        "\n",
        "df = spark.read.option(\"inferschema\",\"true\").option(\"header\",\"true\").csv(\"/content/top_100_saas_companies_2025.csv\")\n",
        "\n",
        "df.printSchema()\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Problem 1: UDF â€“ Standardize Currency Columns\n",
        "\n",
        "from pyspark.sql.functions import udf, col, regexp_replace\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df = df.withColumn(\"Valuation_modified\", regexp_replace(\"Valuation\",r\"\\s*\\(.*\\)\",\"\"))\n",
        "\n",
        "def currency_columns(val):\n",
        "  val = val.replace(\"$\",\"\")\n",
        "  if \"T\" in val:\n",
        "    return float(val.replace(\"T\",\"\"))*1000000000000\n",
        "  if \"B\" in val:\n",
        "    return float(val.replace(\"B\",\"\"))*1000000000\n",
        "  if \"M\" in val:\n",
        "    return float(val.replace(\"M\",\"\"))*1000000\n",
        "\n",
        "currency_udf = udf(currency_columns, DoubleType())\n",
        "\n",
        "df = df.withColumn(\"ARR_Num\", currency_udf(col(\"ARR\"))).withColumn(\"Valuation_Num\", currency_udf(col(\"Valuation_modified\"))).withColumn(\"Funding_Num\", currency_udf(col(\"Total Funding\")))\n",
        "df.select(\"ARR\",\"ARR_Num\",\"Valuation\",\"Valuation_Num\",\"Total Funding\",\"Funding_Num\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4a1fIudtXE0",
        "outputId": "b3f9a82f-42d2-43da-eb13-c01d9c0261e9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+-------------------+-------------+-------------+--------------------+\n",
            "|   ARR|             ARR_Num|          Valuation|Valuation_Num|Total Funding|         Funding_Num|\n",
            "+------+--------------------+-------------------+-------------+-------------+--------------------+\n",
            "| $270B|              2.7E11|                $3T|       3.0E12|          $1B|               1.0E9|\n",
            "|$37.9B|             3.79E10|            $227.8B|     2.278E11|       $65.4M| 6.540000000000001E7|\n",
            "|$19.4B|             1.94E10|              $240B|       2.4E11|        $2.5M|           2500000.0|\n",
            "|$52.9B|             5.29E10|              $350B|       3.5E11|          $2K|                NULL|\n",
            "|$32.5B|             3.25E10|              $215B|      2.15E11|          N/A|                NULL|\n",
            "|$14.4B|             1.44E10|              $180B|       1.8E11|        $273M|              2.73E8|\n",
            "| $8.9B|               8.9E9|              $147B|      1.47E11|       $82.5M|              8.25E7|\n",
            "| $7.3B|               7.3E9|               $65B|       6.5E10|      $249.9M|             2.499E8|\n",
            "| $4.5B|               4.5E9|               $85B|       8.5E10|      $145.5M|             1.455E8|\n",
            "| $7.1B|               7.1E9|               $95B|       9.5E10|      $122.3M|             1.223E8|\n",
            "| $3.5B|               3.5E9|               $55B|       5.5E10|         $60M|               6.0E7|\n",
            "| $2.8B|               2.8E9|               $75B|       7.5E10|        $1.4B|               1.4E9|\n",
            "| $2.2B|               2.2E9|               $32B|       3.2E10|      $100.5M|             1.005E8|\n",
            "| $2.5B|               2.5E9|               $10B|       1.0E10|      $514.3M|5.1429999999999994E8|\n",
            "| $1.7B|               1.7E9|$27.7B (Salesforce)|      2.77E10|        $1.4B|               1.4E9|\n",
            "| $400M|               4.0E8|               $10B|       1.0E10|        $353M|              3.53E8|\n",
            "| $2.1B|               2.1E9|               $44B|       4.4E10|      $147.9M|             1.479E8|\n",
            "| $1.7B|               1.7E9|               $26B|       2.6E10|      $311.2M|             3.112E8|\n",
            "| $2.2B|               2.2E9|               $25B|       2.5E10|      $230.5M|             2.305E8|\n",
            "| $4.1B|4.0999999999999995E9|               $12B|       1.2E10|      $261.3M|             2.613E8|\n",
            "+------+--------------------+-------------------+-------------+-------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 2: Window Function â€“ Identify Top Performers per Industry\n",
        "# Title: Top 2 Companies by Valuation Within Each Industry\n",
        "\n",
        "from pyspark.sql.functions import desc, col, rank\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "windowed_df = Window.partitionBy(\"Industry\").orderBy(col(\"Valuation_Num\").desc())\n",
        "\n",
        "df.withColumn(\"rank\", rank().over(windowed_df)).filter(col(\"rank\")<=2).select(\"Industry\",\"Company Name\",\"Valuation_Num\",\"rank\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge3taZLUx4fX",
        "outputId": "2075c9c0-2dee-46bd-8f44-9e8271cb9181"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------+-------------+----+\n",
            "|            Industry|Company Name|Valuation_Num|rank|\n",
            "+--------------------+------------+-------------+----+\n",
            "|                 APM| AppDynamics|        3.7E9|   1|\n",
            "|                BNPL|      Affirm|       1.2E10|   1|\n",
            "|Business Intellig...|      Looker|        2.6E9|   1|\n",
            "|               CI/CD|    CircleCI|        1.7E9|   1|\n",
            "|                 CRM|  Salesforce|     2.278E11|   1|\n",
            "|        Card Issuing|     Marqeta|        4.3E9|   1|\n",
            "|      Cloud Security|     Zscaler|       3.0E10|   1|\n",
            "|      Cloud Security|    Netskope|        7.5E9|   2|\n",
            "|       Cloud Storage|     Dropbox|        8.5E9|   1|\n",
            "|       Cloud Storage|         Box|        3.5E9|   2|\n",
            "|       Collaboration|        Miro|      1.75E10|   1|\n",
            "|Collaboration Sof...|   Atlassian|       5.5E10|   1|\n",
            "|      Communications|      Twilio|       1.2E10|   1|\n",
            "|      Communications| RingCentral|        5.0E9|   2|\n",
            "|        Construction|     Procore|        9.0E9|   1|\n",
            "|      Contact Center|       Five9|        8.0E9|   1|\n",
            "|     Corporate Cards|        Brex|      1.23E10|   1|\n",
            "|   Creative Software|       Adobe|       2.4E11|   1|\n",
            "|       Customer Data|     Segment|        3.2E9|   1|\n",
            "| Customer Engagement|       Braze|        5.6E9|   1|\n",
            "+--------------------+------------+-------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 3: Window Function â€“ ARR Growth Gaps\n",
        "# Title: Understand Revenue Distribution Among Competitors\n",
        "\n",
        "from pyspark.sql.functions import desc, col, lag\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "windowed_df = Window.partitionBy(\"Industry\").orderBy(col(\"ARR_Num\").desc())\n",
        "\n",
        "df.withColumn(\"lag_ARR_Num\", lag(\"ARR_Num\").over(windowed_df)).filter(col(\"lag_ARR_Num\")-col(\"ARR_Num\")>1000000000).select(\"Industry\",\"ARR_Num\",\"lag_ARR_Num\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUsS5Wz3zieG",
        "outputId": "28e72e79-8a3c-469a-ae4b-4db5b49f4048"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------+--------------------+\n",
            "|           Industry|ARR_Num|         lag_ARR_Num|\n",
            "+-------------------+-------+--------------------+\n",
            "|     Cloud Security|  5.0E8|               1.6E9|\n",
            "|      Cloud Storage|  1.0E9|               2.5E9|\n",
            "|     Communications|  2.2E9|4.0999999999999995E9|\n",
            "|      Cybersecurity|  3.1E9|               7.5E9|\n",
            "|     Data Analytics|  2.2E9|               3.7E9|\n",
            "|           Database|  1.0E8|               1.7E9|\n",
            "|             Design|  6.0E8|               2.0E9|\n",
            "|Enterprise Software|3.25E10|              2.7E11|\n",
            "|           Payments| 1.4E10|             1.97E10|\n",
            "+-------------------+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 4: CASE WHEN â€“ Label Companies by G2 Rating\n",
        "# Title: Classify Companies Based on User Sentiment\n",
        "\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "df = df.withColumn(\"Rating_Tier\", when(col(\"G2 Rating\")>=4.7, \"Excellent\")\n",
        "            .when((col(\"G2 Rating\")>=4.3) & (col(\"G2 Rating\")<4.7), \"Very Good\")\n",
        "            .when((col(\"G2 Rating\")>=4.0) & (col(\"G2 Rating\")<4.3), \"Good\")\n",
        "            .otherwise(\"Average\"))\n",
        "df.select(\"Industry\", \"Company Name\", \"Rating_Tier\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLt_4_TI4T1C",
        "outputId": "34b0f2f2-2dee-414c-bf8d-2c3abf755591"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------+-----------+\n",
            "|            Industry|Company Name|Rating_Tier|\n",
            "+--------------------+------------+-----------+\n",
            "| Enterprise Software|   Microsoft|  Very Good|\n",
            "|                 CRM|  Salesforce|  Very Good|\n",
            "|   Creative Software|       Adobe|  Very Good|\n",
            "|Database & Enterp...|      Oracle|       Good|\n",
            "| Enterprise Software|         SAP|       Good|\n",
            "|  Financial Software|      Intuit|  Very Good|\n",
            "|IT Service Manage...|  ServiceNow|  Very Good|\n",
            "|        HR & Finance|     Workday|       Good|\n",
            "|Video Communications|        Zoom|  Very Good|\n",
            "|          E-commerce|     Shopify|  Very Good|\n",
            "|Collaboration Sof...|   Atlassian|  Very Good|\n",
            "|    Data Warehousing|   Snowflake|  Very Good|\n",
            "|   Marketing & Sales|     HubSpot|  Very Good|\n",
            "|  Digital Agreements|    DocuSign|  Very Good|\n",
            "|  Team Communication|       Slack|  Very Good|\n",
            "|        Productivity|      Notion|  Excellent|\n",
            "|Monitoring & Anal...|     Datadog|  Very Good|\n",
            "|            Database|     MongoDB|  Very Good|\n",
            "| Identity Management|        Okta|  Very Good|\n",
            "|      Communications|      Twilio|  Very Good|\n",
            "+--------------------+------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 5: Join â€“ Investor Tier Enrichment\n",
        "# Title: Understand Impact of Tier-1 Investors\n",
        "\n",
        "from pyspark.sql.functions import split\n",
        "\n",
        "investor_tiers = spark.createDataFrame([\n",
        "    (\"Accel\", \"Tier 1\"),\n",
        "    (\"Sequoia\", \"Tier 1\"),\n",
        "    (\"Andreessen Horowitz\", \"Tier 1\"),\n",
        "    (\"SoftBank\", \"Tier 2\"),\n",
        "    (\"Lightspeed\", \"Tier 2\"),\n",
        "    (\"Unknown\", \"Tier 3\")\n",
        "], [\"Investor\", \"Tier\"])\n",
        "\n",
        "df = df.withColumn(\"list_of_investors\", split(col(\"Top Investors\"),\",\"))\n",
        "df = df.withColumn(\"Investor\",col(\"list_of_investors\")[0])\n",
        "# df.show()\n",
        "\n",
        "joined_df = df.join(investor_tiers, df.Investor==investor_tiers.Investor, \"inner\")\n",
        "# joined_df.show()\n",
        "filtered_df = joined_df.filter((col(\"Tier\")==\"Tier 1\")|(col(\"Tier\")==\"Tier 2\"))\n",
        "filtered_df.select(df.Industry, \"Company Name\", df.Investor, \"Tier\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxBzf3rb-lBa",
        "outputId": "26a68daa-9753-4f14-d383-bdf298faf437"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+-------------------+------+\n",
            "|            Industry|      Company Name|           Investor|  Tier|\n",
            "+--------------------+------------------+-------------------+------+\n",
            "|  Search & Discovery|           Algolia|              Accel|Tier 1|\n",
            "|      Log Management|        Sumo Logic|              Accel|Tier 1|\n",
            "|       Customer Data|           Segment|              Accel|Tier 1|\n",
            "| Customer Engagement|        Freshworks|              Accel|Tier 1|\n",
            "|  Team Communication|             Slack|              Accel|Tier 1|\n",
            "|      Cloud Security|          Netskope|            Sequoia|Tier 1|\n",
            "|   Physical Security|           Verkada|            Sequoia|Tier 1|\n",
            "|Revenue Intelligence|              Gong|            Sequoia|Tier 1|\n",
            "|Experience Manage...|         Qualtrics|            Sequoia|Tier 1|\n",
            "|      Communications|       RingCentral|            Sequoia|Tier 1|\n",
            "|       Cybersecurity|Palo Alto Networks|            Sequoia|Tier 1|\n",
            "|   Product Analytics|         Amplitude|            Sequoia|Tier 1|\n",
            "|      Data Streaming|         Confluent|            Sequoia|Tier 1|\n",
            "|                 RPA|            UiPath|            Sequoia|Tier 1|\n",
            "|       Cloud Storage|           Dropbox|            Sequoia|Tier 1|\n",
            "|              Design|             Canva|            Sequoia|Tier 1|\n",
            "|            Payments|            Stripe|            Sequoia|Tier 1|\n",
            "|            Database|           MongoDB|            Sequoia|Tier 1|\n",
            "|    Data Warehousing|         Snowflake|            Sequoia|Tier 1|\n",
            "| Endpoint Management|            Tanium|Andreessen Horowitz|Tier 1|\n",
            "+--------------------+------------------+-------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 6: Join â€“ Compare with Industry Median\n",
        "# Title: Classify Companies Based on Valuation Position\n",
        "\n",
        "industry_medians = spark.createDataFrame([\n",
        "    (\"Enterprise Software\", 150_000_000_000),\n",
        "    (\"CRM\", 100_000_000_000),\n",
        "    (\"AI\", 70_000_000_000),\n",
        "    (\"HRTech\", 50_000_000_000),\n",
        "], [\"Industry\", \"Median_Valuation\"])\n",
        "\n",
        "joined_df = df.join(industry_medians, df.Industry==industry_medians.Industry, \"inner\")\n",
        "\n",
        "joined_df = joined_df.withColumn(\"Valuation_Position\", when(col(\"Valuation_Num\")>col(\"Median_Valuation\"), \"Median\")\n",
        "              .otherwise(\"Below\"))\n",
        "joined_df.select(df.Industry, \"Company Name\", \"Valuation_Num\", \"Median_Valuation\", \"Valuation_Position\").show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-O3SRGS8Usr",
        "outputId": "afe4d541-fc3d-4382-9c14-e0d0a19f21e5"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------+-------------+----------------+------------------+\n",
            "|           Industry|Company Name|Valuation_Num|Median_Valuation|Valuation_Position|\n",
            "+-------------------+------------+-------------+----------------+------------------+\n",
            "|Enterprise Software|         SAP|      2.15E11|    150000000000|            Median|\n",
            "|Enterprise Software|   Microsoft|       3.0E12|    150000000000|            Median|\n",
            "|                CRM|  Salesforce|     2.278E11|    100000000000|            Median|\n",
            "+-------------------+------------+-------------+----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}